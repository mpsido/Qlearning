{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange\n",
    "\n",
    "class BlackJack:\n",
    "    \n",
    "    cards = 4 * ([ i for i in range(1, 10)] + [10, 10, 10, 10])\n",
    "    def __init__(self):\n",
    "        self.reward = 0\n",
    "        self.done = False\n",
    "        class ActionSpace:\n",
    "            def sample(self):\n",
    "                return randrange(self.n)\n",
    "        self.action_space = ActionSpace()\n",
    "        self.action_space.n = 2\n",
    "        self.force_log = False\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    def render(self):\n",
    "        self.force_log = True\n",
    "        if self.force_log:\n",
    "            log = True\n",
    "    \n",
    "    @classmethod\n",
    "    def draw_card(cls):\n",
    "        return cls.cards[randrange(52)] # in real card games as has prob p(as) 4/52 p(10)=16/52 and the rest 4/52\n",
    "    \n",
    "    def start_game(self, log = False):\n",
    "        if self.force_log:\n",
    "            log = True\n",
    "        return self.distribute(log)\n",
    "    \n",
    "    def reset(self):\n",
    "        state, _, _, _ = self.distribute()\n",
    "        return state\n",
    "    \n",
    "    def distribute(self, log = False):\n",
    "        if self.force_log:\n",
    "            log = True\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.dealer_cards = [BlackJack.draw_card(), BlackJack.draw_card()]\n",
    "        self.player_cards = [BlackJack.draw_card(), BlackJack.draw_card()]\n",
    "        if log: print(\"Dealer:\", self.dealer_cards[0])\n",
    "        if log: print(\"My cards:\", self.player_cards)\n",
    "        if self.my_sum() == 21:\n",
    "            if self.dealer_sum() == 21:\n",
    "                self.reward = 0\n",
    "                self.done = True\n",
    "            else:\n",
    "                self.reward = 1\n",
    "                self.done = True\n",
    "        return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {'Dealer': self.dealer_cards, 'Player': self.player_cards}\n",
    "    \n",
    "    def has_usable_as(self):\n",
    "        if 1 in self.player_cards:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    def step(self, action, log = False):\n",
    "        if self.force_log:\n",
    "            log = True\n",
    "        if (action == 0):\n",
    "            self.hit(log)\n",
    "        elif (action == 1):\n",
    "            self.stick(log)\n",
    "        else:\n",
    "            raise IndexError\n",
    "        return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {'Dealer': self.dealer_cards, 'Player': self.player_cards}\n",
    "    \n",
    "    def hit(self, log = False):\n",
    "        if self.force_log:\n",
    "            log = True\n",
    "        if self.done:\n",
    "            print(\"Game already over\")\n",
    "            return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {'Dealer': self.dealer_cards, 'Player': self.player_cards}\n",
    "        self.player_cards.append(BlackJack.draw_card())\n",
    "        if log: print(\"Hit !\")\n",
    "        if log: print(\"My cards:\", self.player_cards)\n",
    "        if self.my_sum() > 21:\n",
    "            self.reward = -1\n",
    "            self.done = True\n",
    "        elif self.my_sum() == 21:\n",
    "            return self.stick()\n",
    "        return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {'Dealer': self.dealer_cards, 'Player': self.player_cards}\n",
    "        \n",
    "    def stick(self, log = False):\n",
    "        if self.force_log:\n",
    "            log = True\n",
    "        if self.done:\n",
    "            print(\"Game already over\")\n",
    "            return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {'Dealer': self.dealer_cards, 'Player': self.player_cards}\n",
    "        # dealer policy\n",
    "        while (self.dealer_sum() < 17):\n",
    "            self.dealer_cards.append(BlackJack.draw_card())     \n",
    "        if log: print(\"Stick !\")\n",
    "        if log: print(\"Dealer score:\", self.dealer_sum())\n",
    "        if log: print(\"My sum:\", self.my_sum())\n",
    "        my_sum = self.my_sum()\n",
    "        dealer_sum = self.dealer_sum()\n",
    "        if dealer_sum > 21:\n",
    "            self.reward = 1\n",
    "        else:\n",
    "            if my_sum == dealer_sum:\n",
    "                self.reward = 0\n",
    "            elif my_sum == 21:\n",
    "                if dealer_sum != 21:\n",
    "                    self.reward = 1\n",
    "                else:\n",
    "                    self.reward = 0 # both dealer and play have a natural\n",
    "            elif my_sum > dealer_sum:\n",
    "                self.reward = 1\n",
    "            else:\n",
    "                self.reward = -1\n",
    "        self.done = True\n",
    "        return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {'Dealer': self.dealer_cards, 'Player': self.player_cards}\n",
    "        \n",
    "            \n",
    "    @classmethod\n",
    "    def compute_sum(_, cards):\n",
    "        value = sum(cards)\n",
    "        nb_as = cards.count(1)\n",
    "        i = 0\n",
    "        while (i < nb_as and value <= 10):\n",
    "            value += 10\n",
    "            i += 1\n",
    "        return value\n",
    "    \n",
    "    def my_current_sum(self):\n",
    "        return sum(self.player_cards)\n",
    "\n",
    "    def my_sum(self):\n",
    "        return BlackJack.compute_sum(self.player_cards)\n",
    "    \n",
    "    def dealer_sum(self):\n",
    "        return BlackJack.compute_sum(self.dealer_cards)\n",
    "    \n",
    "    def interactive_play(self, action):\n",
    "        if self.done is False:\n",
    "            self.step(action, True)\n",
    "        else:\n",
    "            print(\"Game over\", self.reward)\n",
    "            print(\"Dealer:\", self.dealer_cards)\n",
    "            print(\"My cards:\", self.player_cards)\n",
    "        return (self.dealer_cards[0], self.my_sum(), self.has_usable_as()), self.reward, self.done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackJack = BlackJack()\n",
    "blackJack.distribute(log = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackJack.step(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# state(dealer_showing, my_sum, usable_as)\n",
    "# action 0: hit, 1: stick\n",
    "\n",
    "def basic_hit_policy(state, limit):\n",
    "    if state[1] >= limit:\n",
    "        return 1 #stick\n",
    "    return 0\n",
    "\n",
    "def play_policy(policy):\n",
    "    # Generate episode:\n",
    "    blackJack = BlackJack()\n",
    "    blackJack.distribute()\n",
    "    \n",
    "    states = []\n",
    "    if blackJack.done is False:\n",
    "        states.append((blackJack.dealer_cards[0] - 1, blackJack.my_sum() - 2, blackJack.has_usable_as()))\n",
    "    while blackJack.done is False:\n",
    "        state = ( blackJack.dealer_cards[0] - 1, blackJack.my_sum() - 2, blackJack.has_usable_as() )\n",
    "        states.append(state)\n",
    "        action = policy(state)\n",
    "        blackJack.step(action)\n",
    "    return states, blackJack.reward\n",
    "\n",
    "# 10 - possible dealer cards / 21 - possible sums: 2 - 21 + >21 / 2- Has Ace True or False / 2 - Possible actions\n",
    "def optimal_policy(Q, state):\n",
    "    return Q[state[0], state[1], state[2]].argmax()\n",
    "\n",
    "def update_policy_scores(Q, Returns, states, game_state, policy):\n",
    "    for state in states: # I can assume the states are never repeated\n",
    "        # can also get the \"average\" reward simply by getting the end state\n",
    "        action = optimal_policy(Q, state)\n",
    "        if (state, action) not in Returns:\n",
    "            Returns[(state,action)] = []\n",
    "        Returns[(state,action)].append(game_state)\n",
    "        Q[state[0], state[1], state[2], action] = sum(Returns[(state,action)])/len(Returns[(state,action)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a first round of the game\n",
    "Q = np.zeros((10, 20, 2, 2)) \n",
    "Returns = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_policy = lambda state: basic_hit_policy(state, 20)\n",
    "states, game_state = play_policy(running_policy)\n",
    "update_policy_scores(Q, Returns, states, game_state, running_policy)\n",
    "\n",
    "running_policy = lambda state: optimal_policy(Q, state)\n",
    "for i in range(500):\n",
    "    states, game_state = play_policy(running_policy)\n",
    "    update_policy_scores(Q, Returns, states, game_state, running_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_blackJack():\n",
    "    blackJack = BlackJack()\n",
    "    blackJack.distribute(log = True)\n",
    "\n",
    "    while blackJack.done is False:\n",
    "        state = ( blackJack.dealer_cards[0] - 1, blackJack.my_sum() - 2, blackJack.has_usable_as() )\n",
    "        print(Q[state[0],state[1],state[2]])\n",
    "        action = optimal_policy(Q, state)\n",
    "        # action = basic_hit_policy(state, 17)\n",
    "        _, reward, _, _ = blackJack.interactive_play(action)\n",
    "    return reward\n",
    "\n",
    "total_score = 0\n",
    "for i in range(1000):\n",
    "    game_state = play_blackJack()\n",
    "    total_score += game_state\n",
    "    if game_state == 1:\n",
    "        print(\"*** Win!***\")\n",
    "    elif game_state == 0:\n",
    "        print(\"*** Draw :(***\")\n",
    "    else:\n",
    "        print(\"*** Lose XD ***\")\n",
    "print(\"Total score:\", total_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlearning import *\n",
    "\n",
    "def state_function(state):\n",
    "    if state is None:\n",
    "        raise IndexError\n",
    "    return state\n",
    "env = BlackJack() \n",
    "game = GamePlayer(env, state_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 500\n",
    "alpha = 0.3\n",
    "gamma = 0.9                 # Discounting rate\n",
    "decay_rate = 5          # Exponential decay rate for exploration prob\n",
    "epsilon = 0.1                 # Ehttp://localhost:8888/notebooks/Black-Jack.ipynb#xploration rate\n",
    "#game.erase_training()\n",
    "rewards = game.train(total_episodes, alpha, gamma, epsilon, decay_rate, logEvery = 100)\n",
    "print(\"Total reward average:\", np.mean(rewards))\n",
    "print(len(game.qtable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(5):\n",
    "    state = game.start_game(True)\n",
    "    print(\"****************************************************\")\n",
    "    print(\"EPISODE \", episode)\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    while done is False:\n",
    "    # for step in range(max_steps):\n",
    "        # Take the action (index) that have the maximum expected future reward given that state\n",
    "        new_state, reward, done, info = game.computer_play_step(state)\n",
    "        #game.play_game_step(0)\n",
    "        state = new_state\n",
    "        tot_reward += reward\n",
    "    print(\"Reward:\", tot_reward)\n",
    "game.end_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game.qtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Q learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import qlearning\n",
    "importlib.reload(qlearning)\n",
    "\n",
    "def state_function(state):\n",
    "    if state is None:\n",
    "        raise IndexError\n",
    "    return state\n",
    "env = BlackJack() \n",
    "game = qlearning.GamePlayer(env, state_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 500\n",
    "alpha = 0.3\n",
    "gamma = 0.9                 # Discounting rate\n",
    "decay_rate = 5          # Exponential decay rate for exploration prob\n",
    "epsilon = 0.1                 # Ehttp://localhost:8888/notebooks/Black-Jack.ipynb#xploration rate\n",
    "#game.erase_training()\n",
    "rewards = game.double_q_train(total_episodes, alpha, gamma, epsilon, decay_rate, logEvery = 100)\n",
    "print(\"Total reward average:\", np.mean(rewards))\n",
    "print(len(game.qtable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(game.Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(5):\n",
    "    state = game.start_game(True)\n",
    "    print(\"****************************************************\")\n",
    "    print(\"EPISODE \", episode)\n",
    "    done = False\n",
    "    tot_reward = 0\n",
    "    while done is False:\n",
    "    # for step in range(max_steps):\n",
    "        # Take the action (index) that have the maximum expected future reward given that state\n",
    "        new_state, reward, done, info = game.double_trained_computer_play_step(state)\n",
    "        #game.play_game_step(0)\n",
    "        state = new_state\n",
    "        tot_reward += reward\n",
    "    print(\"Reward:\", tot_reward)\n",
    "game.end_game()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
